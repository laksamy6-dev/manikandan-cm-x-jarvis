# -*- coding: utf-8 -*-
# ==============================================================================
#   PROJECT: CM-X GENESIS V2 (THE TRAINABLE BRAIN)
#   AUTHOR: Boss Manikandan Rajendran & Chellakili
#   PURPOSE: Self-Learning AI with Long-Term Memory (JSON Persistence)
# ==============================================================================

import asyncio
import numpy as np
import time
import json
import os
from collections import deque

# --- 1. THE MEMORY CHIP (à®®à¯‚à®³à¯ˆ à®¨à®¿à®©à¯ˆà®µà®•à®®à¯) ---
# à®‡à®¤à¯à®¤à®¾à®©à¯ à®…à®µà®©à¯‹à®Ÿ "à®Ÿà¯ˆà®°à®¿". à®Ÿà¯†à®¯à¯à®²à®¿ à®•à®¤à¯à®¤à¯à®•à¯à®•à®¿à®±à®¤à¯ˆ à®‡à®¤à¯à®² à®Žà®´à¯à®¤à®¿ à®µà¯ˆà®ªà¯à®ªà®¾à®©à¯.
MEMORY_FILE = "cm_x_brain_memory.json"

class GeneticBrain:
    def __init__(self):
        # à®Ÿà¯€à®ƒà®ªà®¾à®²à¯à®Ÿà¯ à®…à®±à®¿à®µà¯ (à®Žà®¤à¯à®µà¯à®®à¯ à®¤à¯†à®°à®¿à®¯à®¾à®¤à®ªà¯à®ªà¯‹ à®‡à®ªà¯à®ªà®Ÿà®¿ à®¯à¯‹à®šà®¿à®ªà¯à®ªà®¾à®©à¯)
        self.default_weights = {
            "PHYSICS_AGENT": 1.5,   # à®µà¯‡à®•à®®à¯ à®®à®±à¯à®±à¯à®®à¯ à®µà®¿à®šà¯ˆ (à®¨à®®à¯à®® à®¹à¯€à®°à¯‹)
            "TREND_AGENT": 1.0,     # à®šà¯‚à®ªà¯à®ªà®°à¯ à®Ÿà¯à®°à¯†à®£à¯à®Ÿà¯
            "OPTION_CHAIN_AGENT": 1.2, # à®Ÿà¯‡à®Ÿà¯à®Ÿà®¾
            "VOLATILITY_AGENT": 1.0, # à®šà®¨à¯à®¤à¯ˆ à®¨à®¿à®²à®µà®°à®®à¯
            "PATTERN_AGENT": 0.8    # à®•à¯‡à®£à¯à®Ÿà®¿à®²à¯ à®ªà¯‡à®Ÿà¯à®Ÿà®°à¯à®©à¯
        }
        self.weights = self.load_memory() # à®ªà®´à¯ˆà®¯ à®žà®¾à®ªà®•à®¤à¯à®¤à¯ˆ à®®à¯€à®Ÿà¯à®Ÿà¯†à®Ÿà¯à®¤à¯à®¤à®²à¯
        self.learning_rate = 0.05

    def load_memory(self):
        """
        à®•à®®à¯à®ªà¯à®¯à¯‚à®Ÿà¯à®Ÿà®°à¯ à®†à®©à¯ à®†à®© à®‰à®Ÿà®©à¯‡, à®ªà®´à¯ˆà®¯ à®Ÿà¯ˆà®°à®¿à®¯à¯ˆ à®Žà®Ÿà¯à®¤à¯à®¤à¯ à®ªà®Ÿà®¿à®•à¯à®•à¯à®®à¯ à®‡à®Ÿà®®à¯.
        """
        if os.path.exists(MEMORY_FILE):
            try:
                with open(MEMORY_FILE, 'r') as f:
                    data = json.load(f)
                    print(f" ðŸ§  MEMORY RELOADED: à®ªà®´à¯ˆà®¯ à®ªà®¾à®Ÿà®™à¯à®•à®³à¯ à®žà®¾à®ªà®•à®®à¯ à®µà®¨à¯à®¤à¯à®Ÿà¯à®šà¯à®šà¯ à®ªà®¾à®¸à¯!")
                    print(f"    Current IQ Level: {data}")
                    return data
            except:
                print(" âš ï¸ MEMORY CORRUPT: à®ªà¯à®¤à¯à®šà®¾ à®•à®¤à¯à®¤à¯à®•à¯à®• à®†à®°à®®à¯à®ªà®¿à®•à¯à®•à®¿à®±à¯‡à®©à¯.")
                return self.default_weights
        else:
            print(" ðŸ‘¶ NEW BORN: à®‡à®©à¯à®©à¯ˆà®•à¯à®•à¯ à®¤à®¾à®©à¯ à®Žà®©à®•à¯à®•à¯ à®®à¯à®¤à®²à¯ à®¨à®¾à®³à¯.")
            return self.default_weights

    def save_memory(self):
        """
        à®‡à®©à¯à®©à¯ˆà®•à¯à®•à¯ à®•à®¤à¯à®¤à¯à®•à¯à®•à®¿à®Ÿà¯à®Ÿ à®ªà®¾à®Ÿà®¤à¯à®¤à¯ˆ à®Ÿà¯ˆà®°à®¿à®¯à®¿à®²à¯ à®Žà®´à¯à®¤à¯à®¤à®²à¯.
        """
        with open(MEMORY_FILE, 'w') as f:
            json.dump(self.weights, f, indent=4)
        print(" ðŸ’¾ MEMORY SAVED: à®‡à®©à¯à®±à¯ˆà®¯ à®ªà®¾à®Ÿà®®à¯ à®®à¯‚à®³à¯ˆà®¯à®¿à®²à¯ à®à®±à¯à®±à®ªà¯à®ªà®Ÿà¯à®Ÿà®¤à¯.")

    def manual_training(self, agent_name, adjustment):
        """
        GURU MODE: à®¨à¯€à®™à¯à®• (à®ªà®¾à®¸à¯) à®…à®µà®©à¯à®•à¯à®•à¯ à®ªà®¾à®Ÿà®®à¯ à®¨à®Ÿà®¤à¯à®¤à¯à®®à¯ à®‡à®Ÿà®®à¯.
        à®‰à®¤à®¾à®°à®£à®®à¯: "Trend Agent à®ªà®µà®°à¯ˆ à®•à¯‚à®Ÿà¯à®Ÿà¯" (+0.5)
        """
        if agent_name in self.weights:
            self.weights[agent_name] += adjustment
            print(f" ðŸ‘¨â€ðŸ« TEACHER TIP: {agent_name} à®ªà®µà®°à¯ {adjustment} à®®à®¾à®±à¯à®±à®ªà¯à®ªà®Ÿà¯à®Ÿà®¤à¯. New Weight: {self.weights[agent_name]:.2f}")
            self.save_memory()
        else:
            print(" âŒ à®…à®ªà¯à®ªà®Ÿà®¿ à®’à®°à¯ à®à®œà¯†à®£à¯à®Ÿà¯ à®‡à®²à¯à®² à®ªà®¾à®¸à¯!")

    def consult_council(self, physics_score, trend_score, oi_score):
        # à®“à®Ÿà¯à®Ÿà¯ à®ªà¯‹à®Ÿà¯à®®à¯ à®®à¯à®±à¯ˆ (Voting System)
        # à®ªà®¾à®¸à¯, à®‡à®¤à¯à®² à®…à®¨à¯à®¤ 10,000 à®ªà¯‡à®°à¯‹à®Ÿ à®•à®£à®¿à®ªà¯à®ªà¯ à®¨à®Ÿà®•à¯à®•à¯à®®à¯.
        
        # à®‰à®¤à®¾à®°à®£à®¤à¯à®¤à¯à®•à¯à®•à¯ à®šà®¿à®®à¯à®ªà®¿à®³à®¾:
        total_score = (
            (physics_score * self.weights["PHYSICS_AGENT"]) +
            (trend_score * self.weights["TREND_AGENT"]) +
            (oi_score * self.weights["OPTION_CHAIN_AGENT"])
        )
        
        # à®®à¯à®Ÿà®¿à®µà¯ à®Žà®Ÿà¯à®¤à¯à®¤à®²à¯
        decision = "BUY" if total_score > 2 else "SELL" if total_score < -2 else "WAIT"
        return decision, total_score

    def self_correct(self, actual_result, my_decision):
        """
        SELF LEARNING: à®®à¯à®Ÿà®¿à®µà¯ à®¤à®ªà¯à®ªà®¾ à®ªà¯‹à®©à®¾, à®¯à®¾à®°à®¾à®² à®¤à®ªà¯à®ªà®¾à®šà¯à®šà¯à®©à¯ à®•à®£à¯à®Ÿà¯à®ªà®¿à®Ÿà®¿à®šà¯à®šà¯ à®¤à®¿à®°à¯à®¤à¯à®¤à®¿à®•à¯à®•à®¿à®±à®¤à¯.
        """
        # à®‰à®¤à®¾à®°à®£à®®à¯: à®¨à®¾à®©à¯ BUY à®šà¯Šà®©à¯à®©à¯‡à®©à¯, à®†à®©à®¾ à®®à®¾à®°à¯à®•à¯à®•à¯†à®Ÿà¯ à®µà®¿à®´à¯à®¨à¯à®¤à¯à®°à¯à®šà¯à®šà¯ (Wrong Decision)
        if my_decision == "BUY" and actual_result == "DOWN":
            print(" ðŸ˜¡ à®¤à®ªà¯à®ªà®¾à®© à®®à¯à®Ÿà®¿à®µà¯! à®¤à®£à¯à®Ÿà®©à¯ˆ à®•à¯Šà®Ÿà¯à®•à¯à®•à®¿à®±à¯‡à®©à¯...")
            # à®¯à®¾à®°à¯ à®¤à®ªà¯à®ªà®¾ à®µà®´à®¿ à®¨à®Ÿà®¤à¯à®¤à¯à®©à®¤à¯? (à®Ž.à®•à®¾: Trend Agent)
            self.weights["TREND_AGENT"] -= 0.1
            # à®¯à®¾à®°à¯ à®šà®°à®¿à®¯à®¾ à®šà¯Šà®©à¯à®©à®¤à¯? (à®Ž.à®•à®¾: Physics Agent Sell à®šà¯Šà®²à¯à®²à®¿à®¯à®¿à®°à¯à®¨à¯à®¤à®¾ à®…à®µà®©à¯à®•à¯à®•à¯ à®ªà®¾à®°à®¾à®Ÿà¯à®Ÿà¯)
            self.weights["PHYSICS_AGENT"] += 0.05
            
        self.save_memory() # à®‰à®Ÿà®©à¯‡ à®šà¯‡à®µà¯ à®ªà®£à¯à®£à¯!

# --- 2. MAIN TEACHING GROUND (à®ªà®¯à®¿à®±à¯à®šà®¿ à®•à®³à®®à¯) ---
async def main():
    print("----------------------------------------------------------------")
    print("   ðŸ§  CM-X GENESIS V2: THE LEARNING MACHINE")
    print("   ðŸŽ“ Mode: TRAINING & LIVE EXECUTION")
    print("----------------------------------------------------------------")
    
    brain = GeneticBrain()
    
    # --- SCENARIO 1: BOSS TEACHING (à®¨à¯€à®™à¯à®• à®Ÿà®¿à®ªà¯à®¸à¯ à®•à¯Šà®Ÿà¯à®•à¯à®•à¯à®±à¯€à®™à¯à®•) ---
    print("\n--- ðŸ‘¨â€ðŸ« GURU TRAINING SESSION ---")
    print("Boss: 'à®‡à®©à¯à®©à¯ˆà®•à¯à®•à¯ à®®à®¾à®°à¯à®•à¯à®•à¯†à®Ÿà¯ à®°à¯Šà®®à¯à®ª à®†à®Ÿà¯à®¤à¯, Physics à®®à¯‡à®² à®¨à®®à¯à®ªà®¿à®•à¯à®•à¯ˆ à®µà¯ˆ.'")
    brain.manual_training("PHYSICS_AGENT", 0.5) # à®ªà®µà®°à¯ˆ à®•à¯‚à®Ÿà¯à®Ÿà¯à®±à¯‹à®®à¯
    
    # --- SCENARIO 2: LIVE MARKET LEARNING ---
    print("\n--- ðŸ“Š LIVE MARKET ACTION ---")
    
    # Mock Data: Physics says UP (+1), Trend says DOWN (-1), OI says UP (+1)
    phys_input = 1 
    trend_input = -1
    oi_input = 1
    
    decision, score = brain.consult_council(phys_input, trend_input, oi_input)
    print(f" ðŸ¤– AI Decision: {decision} (Score: {score:.2f})")
    
    # --- SCENARIO 3: REALITY CHECK (à®®à®¾à®°à¯à®•à¯à®•à¯†à®Ÿà¯ à®Žà®©à¯à®© à®†à®šà¯à®šà¯?) ---
    # à®®à®¾à®°à¯à®•à¯à®•à¯†à®Ÿà¯ à®¨à®¿à®œà®®à®¾à®µà¯‡ à®®à¯‡à®²à¯‡ à®ªà¯‹à®šà¯à®šà¯à®©à¯ à®µà¯ˆà®ªà¯à®ªà¯‹à®®à¯ (UP)
    actual_market_move = "UP" 
    
    if decision == "BUY" and actual_market_move == "UP":
        print(" âœ… à®µà¯†à®±à¯à®±à®¿! à®šà®°à®¿à®¯à®¾à®© à®•à®£à®¿à®ªà¯à®ªà¯.")
        # à®µà¯†à®±à¯à®±à®¿ à®ªà¯†à®±à¯à®±à®¤à®¾à®² à®†à®Ÿà¯à®Ÿà¯‹à®®à¯‡à®Ÿà¯à®Ÿà®¿à®•à¯à®•à®¾ "Trend Agent" (à®¯à®¾à®°à¯ à®¤à®ªà¯à®ªà®¾ à®šà¯Šà®©à¯à®©à®¾à®©à¯‹) à®¤à®£à¯à®Ÿà®¿à®•à¯à®•à®ªà¯à®ªà®Ÿà¯à®µà®¾à®©à¯.
        # Physics & OI à®ªà®¾à®°à®¾à®Ÿà¯à®Ÿà®ªà¯à®ªà®Ÿà¯à®µà®¾à®°à¯à®•à®³à¯.
        brain.self_correct(actual_market_move, decision)

if __name__ == "__main__":
    asyncio.run(main())
